# responsible_ai

Strengths
 1. Innovative focus – Targets honesty rather than only truthfulness, addressing a unique and meaningful aspect of Responsible AI.
 2. Solid technical foundation – Employs advanced methods such as Representation Engineering and Linear Artificial Tomography (LAT).
 3. Clear and structured workflow – The step-by-step plan (evaluation → extraction → control → comparison → assessment) is logical and feasible.
 4. Strong Responsible AI alignment – Directly relates to transparency, explainability, and safety.


Weaknesses / Improvement Opportunities
 1. Currently focuses mainly on one model family (e.g., LLaMA); future work could extend to other architectures to examine cross-model generality.

Suggestions
 1. In later stages, test the approach on different model families (e.g., Mistral, Gemma, or Falcon) to verify generalization.

- Wang Yang
Oct 12 at 9pm
Please address the feedback above and discuss them with the supervising TA going forward, as these will be important for Demos. Additionally, the proposal did not adequately explain the evaluation plans, e.g., datasets, benchmarks, metrics, etc.

Please contact the assigned TA for your project group and set a 20-minute time to meet in person and demo your project by the due date. 

For this demo, each group must:

- Set up a GitHub repository for the project and add the necessary items (e.g., README, etc.) and collaborators. (Done)
- Include the benchmark datasets and ML models in the repository. (You can share the URLs in the README if GitHub does not permit uploading large datasets.) (gonna be cities, inventors, facts, etc.) (LLaMA, Mistral, Gemma)
- Show installation of the necessary IDEs, frameworks, and environments. (copy from the Repe repo) 
- Run the benchmark models for the prediction. (get data from the previous final report?)
